{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f31a120e",
   "metadata": {},
   "source": [
    "# Intro to sklearn\n",
    "\n",
    "\n",
    "What we are going to cover:\n",
    "\n",
    "0. An end to end Scikit-Learn workflow\n",
    "1. Getting the data ready\n",
    "2. Chose the right estimator/algorithm for our problems\n",
    "3. Fit the model/algo and use them to make prediction\n",
    "4. Evaluating a model\n",
    "5. Improve a model\n",
    "6. Save and load a trained model\n",
    "7. Putting it all together\n",
    "\n",
    "\n",
    "Cheat sheet: https://images.datacamp.com/image/upload/v1676302389/Marketing/Blog/Scikit-Learn_Cheat_Sheet.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0812d0d2",
   "metadata": {},
   "source": [
    "## 0. An end to end Scikit learn workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2be25dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28c5747e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1 Getting the data ready\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "heart_disease = pd.read_csv(\"heart-disease.csv\")\n",
    "heart_disease\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4338d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X (features matrix)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "\n",
    "#Create y (labels)\n",
    "y = heart_disease[\"target\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53db0ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d54e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System:\n",
      "    python: 3.10.10 | packaged by Anaconda, Inc. | (main, Mar 21 2023, 18:39:17) [MSC v.1916 64 bit (AMD64)]\n",
      "executable: C:\\Users\\Franz\\miniconda3\\python.exe\n",
      "   machine: Windows-10-10.0.19044-SP0\n",
      "\n",
      "Python dependencies:\n",
      "      sklearn: 1.2.2\n",
      "          pip: 23.1.2\n",
      "   setuptools: 65.6.3\n",
      "        numpy: 1.23.5\n",
      "        scipy: 1.11.0\n",
      "       Cython: None\n",
      "       pandas: 1.5.2\n",
      "   matplotlib: 3.6.2\n",
      "       joblib: 1.3.0\n",
      "threadpoolctl: 3.1.0\n",
      "\n",
      "Built with OpenMP: True\n",
      "\n",
      "threadpoolctl info:\n",
      "       user_api: blas\n",
      "   internal_api: openblas\n",
      "         prefix: libopenblas\n",
      "       filepath: C:\\Users\\Franz\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "        version: 0.3.20\n",
      "threading_layer: pthreads\n",
      "   architecture: Zen\n",
      "    num_threads: 16\n",
      "\n",
      "       user_api: openmp\n",
      "   internal_api: openmp\n",
      "         prefix: vcomp\n",
      "       filepath: C:\\Users\\Franz\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\.libs\\vcomp140.dll\n",
      "        version: None\n",
      "    num_threads: 16\n",
      "\n",
      "       user_api: blas\n",
      "   internal_api: openblas\n",
      "         prefix: libopenblas\n",
      "       filepath: C:\\Users\\Franz\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy.libs\\libopenblas_v0.3.20-571-g3dec11c6-gcc_10_3_0-c2315440d6b6cef5037bad648efc8c59.dll\n",
      "        version: 0.3.21.dev\n",
      "threading_layer: pthreads\n",
      "   architecture: Zen\n",
      "    num_threads: 16\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.show_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "083b9af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f443fea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "PackageNotInstalledError: Package is not installed in prefix.\n",
      "  prefix: C:\\Users\\Franz\\miniconda3\n",
      "  package name: sklearn\n",
      "\n",
      "\n",
      "sys:1: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x1a5ffce71c0>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\Franz\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\utils\\_process_win32.py:124: ResourceWarning: unclosed file <_io.BufferedWriter name=4>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\Franz\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\utils\\_process_win32.py:124: ResourceWarning: unclosed file <_io.BufferedReader name=5>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\Franz\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\utils\\_process_win32.py:124: ResourceWarning: unclosed file <_io.BufferedReader name=6>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "conda update sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35c206ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\franz\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\franz\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\franz\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (1.11.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\franz\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (1.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\franz\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x1a5ffcff5e0>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00018f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. Choose the right model and hyperparameters\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "#We'll keep the default hyperparameters\n",
    "clf.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6537463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a651831",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2947c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a prediction\n",
    "y_preds = clf.predict(X_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fc9b232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168    0\n",
       "242    0\n",
       "57     1\n",
       "85     1\n",
       "102    1\n",
       "      ..\n",
       "157    1\n",
       "279    0\n",
       "72     1\n",
       "178    0\n",
       "186    0\n",
       "Name: target, Length: 61, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8e1ff0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. Evaluate the model\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2896acdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4840776f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85        31\n",
      "           1       0.84      0.87      0.85        30\n",
      "\n",
      "    accuracy                           0.85        61\n",
      "   macro avg       0.85      0.85      0.85        61\n",
      "weighted avg       0.85      0.85      0.85        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8b9bac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26,  5],\n",
       "       [ 4, 26]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26f276b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bfdb627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying model with 10 estimators...\n",
      "Model accuracy on test set: 81.97%\n",
      " \n",
      "Trying model with 20 estimators...\n",
      "Model accuracy on test set: 83.61%\n",
      " \n",
      "Trying model with 30 estimators...\n",
      "Model accuracy on test set: 85.25%\n",
      " \n",
      "Trying model with 40 estimators...\n",
      "Model accuracy on test set: 83.61%\n",
      " \n",
      "Trying model with 50 estimators...\n",
      "Model accuracy on test set: 86.89%\n",
      " \n",
      "Trying model with 60 estimators...\n",
      "Model accuracy on test set: 83.61%\n",
      " \n",
      "Trying model with 70 estimators...\n",
      "Model accuracy on test set: 81.97%\n",
      " \n",
      "Trying model with 80 estimators...\n",
      "Model accuracy on test set: 88.52%\n",
      " \n",
      "Trying model with 90 estimators...\n",
      "Model accuracy on test set: 85.25%\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#5. Improve the model\n",
    "#Try different amount of n_estimators\n",
    "\n",
    "np.random.seed(42)\n",
    "for i in range(10, 100, 10):\n",
    "    print(f\"Trying model with {i} estimators...\")\n",
    "    clf = RandomForestClassifier(n_estimators=i).fit(X_train, y_train)\n",
    "    print(f\"Model accuracy on test set: {clf.score(X_test, y_test) * 100:.2f}%\")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66718a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franz\\AppData\\Local\\Temp\\ipykernel_3540\\3424644202.py:4: ResourceWarning: unclosed file <_io.BufferedWriter name='random_forest_model_1.pkl'>\n",
      "  pickle.dump(clf, open(\"random_forest_model_1.pkl\", \"wb\"))\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "# 6. Save the model and load it\n",
    "import pickle\n",
    "\n",
    "pickle.dump(clf, open(\"random_forest_model_1.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afb0d2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franz\\AppData\\Local\\Temp\\ipykernel_3540\\901759550.py:1: ResourceWarning: unclosed file <_io.BufferedReader name='random_forest_model_1.pkl'>\n",
      "  loaded_model = pickle.load(open(\"random_forest_model_1.pkl\", \"rb\"))\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(\"random_forest_model_1.pkl\", \"rb\"))\n",
    "loaded_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc81fcc2",
   "metadata": {},
   "source": [
    "## 1. Getting our data ready to be used with machine learning\n",
    "\n",
    "Three main things we have to do\n",
    "1. Split the data into features and labels (usually \"X\" and \"y\")\n",
    "2. Filling (also called umputing) or disregarding missing values\n",
    "3. Converting non-numerical values to numerical values (also called feature encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fb4551f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1604fdd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  \n",
       "0   0     1  \n",
       "1   0     2  \n",
       "2   0     2  \n",
       "3   0     2  \n",
       "4   0     2  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2251917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = heart_disease[\"target\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae7ab83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3ac63b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((242, 13), (61, 13), (242,), (61,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5341806",
   "metadata": {},
   "source": [
    "### 1.1. Make sure it is all numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "407d30bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431</td>\n",
       "      <td>4</td>\n",
       "      <td>15323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714</td>\n",
       "      <td>5</td>\n",
       "      <td>19943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714</td>\n",
       "      <td>4</td>\n",
       "      <td>28343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365</td>\n",
       "      <td>4</td>\n",
       "      <td>13434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577</td>\n",
       "      <td>3</td>\n",
       "      <td>14043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Make Colour  Odometer (KM)  Doors  Price\n",
       "0   Honda  White          35431      4  15323\n",
       "1     BMW   Blue         192714      5  19943\n",
       "2   Honda  White          84714      4  28343\n",
       "3  Toyota  White         154365      4  13434\n",
       "4  Nissan   Blue         181577      3  14043"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales = pd.read_csv(\"car-sales-extended.csv\")\n",
    "car_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8ead8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(car_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79f3ba3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             object\n",
       "Colour           object\n",
       "Odometer (KM)     int64\n",
       "Doors             int64\n",
       "Price             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f9d76af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into X/y\n",
    "X = car_sales.drop(\"Price\", axis=1)\n",
    "y = car_sales[\"Price\"]\n",
    "\n",
    "#Split into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b7036bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Toyota'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [30], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestRegressor()\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mscore(X_test, y_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:345\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 345\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    349\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Toyota'"
     ]
    }
   ],
   "source": [
    "#Build machine learning model\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93986dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                  one_hot,\n",
    "                                  categorical_features)],\n",
    "                                 remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feb72e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(transformed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039cb50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(car_sales[[\"Make\", \"Colour\", \"Doors\"]])\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebde11b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's refit the model\n",
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X,\n",
    "                                                   y,\n",
    "                                                   test_size=0.2)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cda310",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a50b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing = pd.read_csv(\"car-sales-extended-missing-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8848419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdaeddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new X and y\n",
    "X = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923f167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try and convert data to numbers\n",
    "\n",
    "#Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                  one_hot,\n",
    "                                  categorical_features)],\n",
    "                                 remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6096664c",
   "metadata": {},
   "source": [
    "#### Option 1: Fill missing data with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4e2461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill the \"Make\" column \n",
    "car_sales_missing[\"Make\"].fillna(\"missing\", inplace=True)\n",
    "\n",
    "#Fill the \"Colour\" column\n",
    "car_sales_missing[\"Colour\"].fillna(\"missing\", inplace=True)\n",
    "\n",
    "#Fill the \"Odomter\" column\n",
    "car_sales_missing[\"Odometer (KM)\"].fillna(car_sales_missing[\"Odometer (KM)\"].mean(), inplace=True)\n",
    "\n",
    "#Fill the \"Doors\" columns\n",
    "\n",
    "car_sales_missing[\"Doors\"].fillna(4, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5bba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check out dataframe\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd99054",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows with missing price value\n",
    "\n",
    "car_sales_missing.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea1f82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6a7a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(car_sales_missing) #We removed 50 unnecessary rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1669e864",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e9c72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try and convert data to numbers\n",
    "\n",
    "#Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                  one_hot,\n",
    "                                  categorical_features)],\n",
    "                                 remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(car_sales_missing)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bca759",
   "metadata": {},
   "source": [
    "### Option 2: Fill missing values with scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5f4b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing = pd.read_csv(\"car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b82a545",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0742f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the rows with no values in  Price\n",
    "car_sales_missing.dropna(subset=[\"Price\"], inplace=True)\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c59f184",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into X and y\n",
    "X = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29ec9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42f6eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill missing values with Scikit-Learn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#Fill Categorical values with missing and numerical values with mean\n",
    "cat_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"missing\")\n",
    "door_imputer = SimpleImputer(strategy=\"constant\", fill_value=4)\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "#Define columns\n",
    "cat_features = [\"Make\", \"Colour\"]\n",
    "door_features = [\"Doors\"]\n",
    "num_features = [\"Odometer (KM)\"]\n",
    "\n",
    "#Create an imputer (sth that fills missing data)\n",
    "imputer = ColumnTransformer([\n",
    "    (\"cat_imputer\", cat_imputer, cat_features),\n",
    "    (\"door_imputer\", door_imputer, door_features),\n",
    "    (\"num_imputer\", num_imputer, num_features)\n",
    "])\n",
    "\n",
    "#Transform the data\n",
    "filled_X = imputer.fit_transform(X)\n",
    "filled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6ad538",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_filled = pd.DataFrame(filled_X, columns=[\"Make\", \"Colours\", \"Doors\", \"Odometer (KM)\"])\n",
    "car_sales_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82a6d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74f53bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = car_sales_filled\n",
    "y = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dd7874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try and convert data to numbers\n",
    "\n",
    "#Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                  one_hot,\n",
    "                                  categorical_features)],\n",
    "                                 remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(car_sales_filled)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeb590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have got our data as numbers and filled (no missing values)\n",
    "\n",
    "np.random.seed(42)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ee5bd0",
   "metadata": {},
   "source": [
    "## 2. Choosing the right estimator/algorithm for your problem\n",
    "\n",
    "Some things to note:\n",
    "* Sklearn refers to machine learning models, algorithms as estimators\n",
    "* Classificatio problem - predicting a category (heart disease or not)\n",
    "* Sometimes you will see \"clf\" (short for classifier) used as a classification estimator\n",
    "* Regression problem - predicting a number (selling price of a car)\n",
    "\n",
    "If your are working on a machine learning problem and looking to use sklearn and not sure what model you should use, look up the scikit-learn machine learning map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d62f19",
   "metadata": {},
   "source": [
    "### 2.1. Picking a machine learning model for a regression problem\n",
    "\n",
    "Let's use the California Housing data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f5fcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get California Housing data set\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dad286",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = pd.DataFrame(housing[\"data\"], columns=housing[\"feature_names\"])\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc097c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df[\"target\"] = housing[\"target\"]\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f99db4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = housing_df.drop(\"MedHouseVal\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d972096",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff8bc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import algorithm\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#Create the data\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"] #median house price in $100,000s\n",
    "\n",
    "#Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#Instantiate and fit the model (on the training set)\n",
    "model = Ridge()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Check the score of the model (on the test set)\n",
    "model.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e04243",
   "metadata": {},
   "source": [
    "What if \"Ridge\" didn't work or the score didn't fit our needs?\n",
    "\n",
    "Well, we could always try a different model...\n",
    "\n",
    "How about we try an ensemble model\n",
    "\n",
    "An ensemble is a combination of smaller models than just a single model. This combination can yield to better results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055e84d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the RandomForestRegressor model class from the ensemble module \n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#Create the data\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "#Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#Create RandomForest model\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train )\n",
    "\n",
    "#Check the score of the model (on the test set)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4da92e",
   "metadata": {},
   "source": [
    "## 2.2. Picking a machine learning model for a classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376f516e",
   "metadata": {},
   "source": [
    "Let's go to the map: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da179656",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease = pd.read_csv(\"heart-disease.csv\")\n",
    "heart_disease.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf9a46e",
   "metadata": {},
   "source": [
    "Consulting the map, tells to try LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3f5314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the LinearSVC estimator class\n",
    "from sklearn.svm import LinearSVC \n",
    "\n",
    "#Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#Make the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "\n",
    "#Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#Instatiate LinearSVC\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate the model\n",
    "clf.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90b6644",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c87c8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the RandomForest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "#Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#Make the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "\n",
    "#Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#Instatiate Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate the model\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30af7c9b",
   "metadata": {},
   "source": [
    "Tidbit:\n",
    "\n",
    "    1. If you have structured data, use ensemble methods\n",
    "    \n",
    "    2. If you have unstructured data, use deep learning or transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b47d8b1",
   "metadata": {},
   "source": [
    "## 3. Fit the  model/algorithm and our data and use it to make predictions\n",
    "\n",
    "### 3-1 Fitting the model to the data\n",
    "\n",
    "* X = features, data, feature variables\n",
    "* y = labels, targets, target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5118fa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the RandomForest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "#Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#Make the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "\n",
    "#Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#Instatiate Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Fit the model to the data (training the ML model)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate the Random Classifier model (Use the patterns the model has learned)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b172f533",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3955cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732e8372",
   "metadata": {},
   "source": [
    "## 3.2 Make predictions using a machine learning model\n",
    "\n",
    "2 ways to make predictions:\n",
    "1. predict()\n",
    "\n",
    "2. predict_proba()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0458cb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dc9f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a trained model to make predicitons\n",
    "\n",
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f71969",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c8c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predictions to truth labels to evaluate the model\n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "test = y_preds == y_test\n",
    "np.array(test) #Nach dem Vergleich erhÃ¤lt man eine Liste von Wahrheitswerten [True, Fale, Flase....]\n",
    "np.mean(test) #Berechnet den Durchschnitt (arithmetisch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5a05aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748c6f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e34d6b",
   "metadata": {},
   "source": [
    "Make predictions with 'predict_proba( )'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0667c33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_proba()return predict probabilities of a classification label\n",
    "clf.predict_proba(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deb9c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's predict on the same data\n",
    "clf.predict(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81f72c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98183e1",
   "metadata": {},
   "source": [
    "'predict()' can also be used for regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490cd3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240be368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#Create the data\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "#Split data into test and train data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#Create model instance\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "#Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions\n",
    "y_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97107209",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9240427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeccfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5482afbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f3638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the predictions to the truth\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2c670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df[\"preds\"] = y_preds\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90276c63",
   "metadata": {},
   "source": [
    "## 4. Evaluating a machine learn model\n",
    "\n",
    "Three ways to evaluate scikit learn models/estimators\n",
    "\n",
    "1. Estimator's built-in \"score()\" method\n",
    "2. The \"scoring\" parameter\n",
    "3. The problem-specific metric functions\n",
    "\n",
    "You can read more about this here:\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a501b9e",
   "metadata": {},
   "source": [
    "### 4.1 Evaluating a model with the score method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa28d2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the RandomForest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "#Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#Make the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "\n",
    "#Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#Instatiate Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Fit the model to the data (training the ML model)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate the Random Classifier model (Use the patterns the model has learned)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0aad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_train, y_train) #The model was trained on X_train, y_train, hence the models score is 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1022fb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2464d1b4",
   "metadata": {},
   "source": [
    "Let's use the score() on our regression problem..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47dca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#Create the data\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "#Split data into test and train data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#Create model instance\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "#Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca1ed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test) #The defailt score evaluation metric is r_squared for regression algorithms (1.0 is highest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85cc850",
   "metadata": {},
   "source": [
    "## 4.2 Evaluating a model using the scoring parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd285702",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import score library\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Import the RandomForest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "#Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#Make the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "\n",
    "#Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#Instatiate Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Fit the model to the data (training the ML model)\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7db867",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4481d0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(clf, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ab790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "#Single training and test split score\n",
    "clf_single_score = clf.score(X_test, y_test)\n",
    "\n",
    "#Take the mean of 5-fold cross-validation score\n",
    "clf_cross_val_score = np.mean(cross_val_score(clf, X, y, cv=5))\n",
    "\n",
    "#compare the two\n",
    "\n",
    "clf_single_score, clf_cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e96dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Default scoring parameter of classifier = mean accuracy\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bb231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring parameter set to None by default\n",
    "cross_val_score(clf, X, y, cv=5, scoring=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ecd5be",
   "metadata": {},
   "source": [
    "### 4.2.1. Classification  model evaluation metrics\n",
    "\n",
    "1. Accuracy\n",
    "2. Area under ROC curve\n",
    "3. Confusion matrix\n",
    "4. Classification Report\n",
    "\n",
    "**Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a94cdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69febb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "cross_val_score = cross_val_score(clf, X, y, cv=5)\n",
    "cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a71a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fccf713",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Heart Disease Classifier Accuracy: {np.mean(cross_val_score) *100:.2f}\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d0434a",
   "metadata": {},
   "source": [
    "**Area under the receiver operatung characteristic curve (AUC/ROC)*\n",
    "\n",
    "* Area under curve\n",
    "* ROC curve\n",
    "\n",
    "ROC curves are a comparison of a model's true positive rate (tpr) vs. a models fals positive rate (fpr)\n",
    "\n",
    "* True positive = model predicts 1 when truth is 1 \n",
    "* Flase positive = model predicts 1 when truth is 0\n",
    "* True negative = model predicts 0 when truth is 0\n",
    "* False negative = model predicts 0 when truth is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X_test...\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23695d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve \n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Make predictions with probabilites\n",
    "y_probs = clf.predict_proba(X_test)\n",
    "\n",
    "y_probs[:10], len(y_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a8abdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_positive = y_probs[:, 1]\n",
    "y_probs_positive[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cc12a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate fpr, tpr and thresholds\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs_positive)\n",
    "\n",
    "#Check the false positive rates\n",
    "fpr, tpr, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630c1b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function for plotting ROC curves\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    \"\"\"\n",
    "    Plots a ROC curve fiven the false positive rate (fpr)\n",
    "    and true positve rate (tpr) of a model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Plot roc curve\n",
    "    plt.plot(fpr, tpr, color=\"orange\", label=\"ROC\")\n",
    "    \n",
    "    #Plot line with no predictive power (baseline)\n",
    "    plt.plot([0, 1], [0, 1], color=\"darkblue\", linestyle=\"--\", label=\"Guessing\")\n",
    "    \n",
    "    #Customize the plot\n",
    "    plt.xlabel(\"False positive rate (fpr)\")\n",
    "    plt.ylabel(\"True positive rate (tpr)\")\n",
    "    plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab64bb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, y_probs_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309368b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot perfect ROC curve and AUC score\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test)\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fb5914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfect AUC score\n",
    "roc_auc_score(y_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d59878b",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3839589f",
   "metadata": {},
   "source": [
    "A confusion matrix is a quick way to compare the labels a model predicts and the actual labels it was supposed to predict. \n",
    "\n",
    "In essence, giving you an idea of where the model is getting confused.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41ac86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff82a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix with pd.crosstab()\n",
    "\n",
    "pd.crosstab(y_test, y_preds, \n",
    "            rownames=[\"Actual Label\"],\n",
    "            colnames=[\"Predicted Labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c454887",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda activate C:\\Users\\Franz\\Desktop\\sample_project_1\\env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ad7b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda env list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f598164",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install --yes seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fba9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make our confusion matrix more visual with seaborn heatmap()\n",
    "import seaborn as sns\n",
    "\n",
    "#Set the font scale \n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "#Create a confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_preds)\n",
    "\n",
    "#Plot using seaborn\n",
    "sns.heatmap(conf_mat);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6637c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f97bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.crosstab(y_test, y_preds, \n",
    "            rownames=[\"Actual Label\"],\n",
    "            colnames=[\"Predicted Labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bae75d4",
   "metadata": {},
   "source": [
    "### Creating a confusion matrox using scikit learn\n",
    "\n",
    "To use a confusion matrix with scikit learn you need version 1.0+ of sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a87dfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b35d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(estimator=clf, X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b678d529",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_true=y_test, y_pred=y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6d5050",
   "metadata": {},
   "source": [
    "**Classsification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1834de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b41d8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where precision and recall become valuable\n",
    "disease_true = np.zeros(10000)\n",
    "disease_true[0] = 1 # only one positive case\n",
    "\n",
    "\n",
    "disease_preds = np.zeros(10000)\n",
    "\n",
    "pd.DataFrame(classification_report(disease_true, disease_preds, output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd30930",
   "metadata": {},
   "source": [
    "**To summarize classification metrics:**\n",
    "    \n",
    "   * Accuracy is a good measure to start with if all classes are balanced (e.g. same amount of samples)\n",
    "    \n",
    "   * Precision and recall become more important when classes are imbalanced\n",
    "    \n",
    "   * If flase positive predictions are worse than false negatives, aim for higher precision\n",
    "    \n",
    "   * If false negative predictions are worse than false positives, aim for higher recall\n",
    "    \n",
    "   * F-1 score is a combination of precision and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f68b1f2",
   "metadata": {},
   "source": [
    "### 4.2. Regression model evaluation metrics\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "The one's we are going to cover are:\n",
    "\n",
    "1. R^2 or coefficient of determination\n",
    "2. Mean absolute error (MAE)\n",
    "3. Mean squared error (MSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e15c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "housing_df = pd.DataFrame(housing[\"data\"], columns=housing[\"feature_names\"])\n",
    "housing_df[\"target\"] = housing[\"target\"]\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc89f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e203d16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d607d14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eabf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54a7c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#Fill an array with y_test mean()\n",
    "y_test_mean = np.full(len(y_test), y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f29a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_mean[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d91a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_test_mean) #if the model would predict only mean values, the R2 would be 0. A perfect model would achieve 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae33a95",
   "metadata": {},
   "source": [
    "**Mean absolute error (MAE)**\n",
    "\n",
    "MAE is the average of the absolute differences between predictions and actual values. \n",
    "It gives you an idea of how wrong your models predictions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ccd31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_preds)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ae326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5f7695",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2b22b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"actual values\": y_test,\n",
    "                       \"predicted values\": y_preds})\n",
    "\n",
    "df[\"differences\"] = df[\"predicted values\"] - df[\"actual values\"]\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337429df",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(df[\"differences\"]).mean() #sames as the mae (average of absolute difference values between predicted and true data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4264fc4f",
   "metadata": {},
   "source": [
    "**Mean Squared Error (MSE)**\n",
    "\n",
    "MSE is the mean of the square of the mean of the errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e2a16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean squared error\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_preds)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d53a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"squared differences\"] = np.square(df[\"differences\"])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52800abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate MSE by hand\n",
    "\n",
    "squared = np.square(df[\"differences\"])\n",
    "\n",
    "squared.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ea8fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large_error = df.copy()\n",
    "df_large_error.iloc[0][\"squared_differences\"] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b986098",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large_error.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5580c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate MSE with large error\n",
    "\n",
    "df_large_error[\"squared differences\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a163fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large_error2 = df_large_error.copy()\n",
    "\n",
    "df_large_error2.iloc[1:1000] = 20\n",
    "df_large_error2.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5efad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large_error2[\"squared differences\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c9f469",
   "metadata": {},
   "source": [
    "### 4.2.3. Finally using the scoring() parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c05686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397c816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "#Cross-validation accuracy\n",
    "\n",
    "cv_acc = cross_val_score(clf, X, y, cv=5, scoring=None)  #if scoring=None, estimators default scoring metric is used (accuracy for classification method)\n",
    "\n",
    "cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e3ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validated accuracy \n",
    "print(f\"The cross-validated accuracy is: {np.mean(cv_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e423e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "cv_acc = cross_val_score(clf, X, y, cv=5, scoring=\"accuracy\")\n",
    "# Cross-validated accuracy \n",
    "print(f\"The cross-validated accuracy is: {np.mean(cv_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c38c2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision\n",
    "np.random.seed(42)\n",
    "cv_precision = cross_val_score(clf, X, y, cv=5, scoring=\"precision\")\n",
    "cv_precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dfacc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The cross-validated precision is: {np.mean(cv_precision)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc3a194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recall \n",
    "np.random.seed(42)\n",
    "cv_recall = cross_val_score(clf, X, y, cv=5, scoring=\"recall\")\n",
    "cv_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c3971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validated accuracy \n",
    "print(f\"The cross-validated accuracy is: {np.mean(cv_recall)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9792dea",
   "metadata": {},
   "source": [
    "Let's see the \"scoring\" parameter being used for regression problem..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd3469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "housing_df = pd.DataFrame(housing[\"data\"], columns=housing[\"feature_names\"])\n",
    "housing_df[\"target\"] = housing[\"target\"]\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164ae216",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77db7696",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "cv_r2 = cross_val_score(model, X, y, cv=3, scoring=None)\n",
    "np.mean(cv_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06888d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f09cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean squared error\n",
    "np.random.seed(42)\n",
    "cv_mse = cross_val_score(model, X, y, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "np.mean(cv_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affc51c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f91d4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean absolute error\n",
    "\n",
    "np.random.seed(42)\n",
    "cv_mae = cross_val_score(model, X, y, cv=5, scoring=\"neg_mean_absolute_error\")\n",
    "np.mean(cv_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3ad630",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a3cc8c",
   "metadata": {},
   "source": [
    "## 4.3. Using different evaluation metrics as Scikit-Learn functions\n",
    "\n",
    "The 3rd way to evaluate scikit-learn machine learning models/estimators is to using the sklearn.metrics modules. See https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcffa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "#Create X & y\n",
    "\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "#split the data \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "#Create the model\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "#Evaluate the model\n",
    "print(\"Classifier metrics on the test set\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, clf.predict(X_test))*100:.2f}%\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_preds)*100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, y_preds)*100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_test, y_preds)*100:.2f}%\")\n",
    "print(f\"F1: {f1_score(y_test, y_preds)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f664cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create X & y\n",
    "\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "\n",
    "#Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#Create model\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "#Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Make predicitions\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "#Evaluate the model using evaluation functions\n",
    "\n",
    "print(\"Regression metrics on the test set\")\n",
    "print(f\"R2: {r2_score(y_test, y_preds)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_preds)}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba75ff1",
   "metadata": {},
   "source": [
    "## 5. Improving a model\n",
    "\n",
    "First predictions = baseline predictions.\n",
    "\n",
    "First model = baseline model.\n",
    "\n",
    "**From a data perspective:**\n",
    "* Could we collect more data? (generally, the more data, the better)\n",
    "* Could we improve our data?\n",
    "\n",
    "**From a model perspective:**\n",
    "* Is there a better model we could use?\n",
    "* Could we improve the current model?\n",
    "\n",
    "**Hyperparameters vs. Parameters**\n",
    "Parameters = Model finds the patterns in data\n",
    "\n",
    "Hyperparameter = Settings in a model you can (potentially) improve its ability to find patterns\n",
    "\n",
    "Three ways to adjust hyperparameters:\n",
    "1. By hand\n",
    "2. Randomly with RandomSearchCV\n",
    "3. Exhaustively with GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d0664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8860793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding Hyperparameters of a model\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac3e062",
   "metadata": {},
   "source": [
    "### 5.1 Tuning hyperparameters by hand\n",
    "\n",
    "Let's make 3 sets, training validation and test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a343f72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081996a7",
   "metadata": {},
   "source": [
    "We are going to try and adjust: \n",
    "   * max_depth\n",
    "   * max_features\n",
    "   * min_samples_leaf\n",
    "   * min_samples_split\n",
    "   * n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffa40b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    Performs evaluation comparison on y_true labels vs. y_pred labels. \n",
    "    on a classification model.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_preds)\n",
    "    precision = precision_score(y_true, y_preds)\n",
    "    recall = recall_score(y_true, y_preds)\n",
    "    f1 = f1_score(y_true, y_preds)\n",
    "    metrics_dict = {\"accuracy\": round(accuracy, 2),\n",
    "                   \"precision\": round(precision, 2),\n",
    "                   \"recall\": round(recall, 2),\n",
    "                   \"f1\": round(f1, 2)}\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1: {f1:.2f}\")\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eabcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#Shuffle the data\n",
    "heart_disease_shuffled = heart_disease.sample(frac=1)\n",
    "\n",
    "#Split into X and y\n",
    "\n",
    "X = heart_disease_shuffled.drop(\"target\", axis=1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "#Split the data into train, validation & test sets\n",
    "train_split = round(0.7 * len(heart_disease_shuffled)) #70% of data\n",
    "valid_split = round(train_split + 0.15 * len(heart_disease_shuffled))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_valid, y_valid = X[train_split:valid_split], y[train_split:valid_split]\n",
    "X_test, y_test = X[valid_split:], y[valid_split:]\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Make baseline predictions\n",
    "y_preds = clf.predict(X_valid)\n",
    "\n",
    "\n",
    "#Evaluate the classifier on the validation set\n",
    "baseline_metrics = evaluate_preds(y_valid, y_preds)\n",
    "baseline_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfc4b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e99199",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "#Create a second classifier with different hyperparameters\n",
    "\n",
    "clf_2 = RandomForestClassifier(n_estimators=100)\n",
    "clf_2.fit(X_train, y_train)\n",
    "\n",
    "#Make prediction with different hyperparameters\n",
    "y_preds2 = clf_2.predict(X_valid)\n",
    "\n",
    "#Evaluate the 2nd classifier\n",
    "clf_2_metrics = evaluate_preds(y_valid, y_preds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9293b50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_3 = RandomForestClassifier(n_estimators=100,\n",
    "                              max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd37bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5.2. Hyperparameter tuning with RandomizedSearchCV\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "grid = {\"n_estimators\": [10, 100, 200, 500, 1000, 1200], \n",
    "       \"max_depth\": [None, 5, 10, 20, 30],\n",
    "       \"max_features\": [\"auto\", \"sqrt\"],\n",
    "       \"min_samples_split\": [2, 4, 6],\n",
    "       \"min_samples_leaf\": [1, 2, 4]}\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#Split into X and y \n",
    "\n",
    "X = heart_disease_shuffled.drop(\"target\", axis=1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "#Split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#Instantiate RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_jobs=1)\n",
    "\n",
    "#Setup Randomized SearchCV\n",
    "rs_clf = RandomizedSearchCV(estimator=clf, \n",
    "                           param_distributions=grid,\n",
    "                           n_iter=10, #number of models to try\n",
    "                           cv=5,\n",
    "                           verbose=2)\n",
    "\n",
    "#Fit the RandomizedSearchCV version of clf\n",
    "rs_clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4f6db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_clf.best_params_  #Which hyperparameters resulted in the best results. \n",
    "#When whe use predict() the model will now use these optimized hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430a13bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions with the best hyperparameters\n",
    "rs_y_preds = rs_clf.predict(X_test)\n",
    "\n",
    "#Evaluate the metrics\n",
    "rs_metrics = evaluate_preds(y_test, rs_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057dea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5.3. Hyperparameter tuninig with GridSearchCV\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06993baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_2 = {'n_estimators': [100, 200, 500],\n",
    "          'max_depth': [None],\n",
    "          'max_features': ['auto', 'sqrt'],\n",
    "          'min_samples_split': [6],\n",
    "          'min_samples_leaf': [1, 2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2498d878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#Split into X and y \n",
    "\n",
    "X = heart_disease_shuffled.drop(\"target\", axis=1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "#Split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#Instantiate RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_jobs=1)\n",
    "\n",
    "#Setup GridSearchCV\n",
    "gs_clf = GridSearchCV(estimator=clf, \n",
    "                      param_grid=grid_2,\n",
    "                      cv=5,\n",
    "                      verbose=2)\n",
    "\n",
    "#Fit the GridSearchCV version of clf\n",
    "gs_clf.fit(X_train, y_train);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803165de",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_y_preds = gs_clf.predict(X_test)\n",
    "\n",
    "#evaluate the predictions\n",
    "gs_metrics = evaluate_preds(y_test, gs_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb83387",
   "metadata": {},
   "source": [
    "Let's compare our different models metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a085705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_metrics = pd.DataFrame({\"baseline\": baseline_metrics,\n",
    "                               \"clf_2\": clf_2_metrics,\n",
    "                               \"random_search\": rs_metrics,\n",
    "                               \"grid search\": gs_metrics}\n",
    "                              )\n",
    "\n",
    "compare_metrics.plot.bar(figsize=(10,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1813904a",
   "metadata": {},
   "source": [
    "## 6. Saving and loading machine learning models\n",
    "\n",
    "Two ways to save and loard ml models:\n",
    "1. Python \"pickle\" module\n",
    "2. With the \"joblib\" module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b6f299",
   "metadata": {},
   "source": [
    "**Pickle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3924d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save an existing model to file\n",
    "\n",
    "pickle.dump(gs_clf, open(\"gs_random_forest_model_1.pkl\", \"wb\"))  #wb mean write binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb59af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a saved model \n",
    "\n",
    "loaded_pickle_model = pickle.load(open(\"gs_random_forest_model_1.pkl\", \"rb\")) #rb means read binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2204f079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make prediction\n",
    "pickle_y_preds = loaded_pickle_model.predict(X_test)\n",
    "evaluate_preds(y_test, pickle_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaca179",
   "metadata": {},
   "source": [
    "**Joblib**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ab09bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "#Save model to file\n",
    "\n",
    "dump(gs_clf, filename=\"gs_random_forest_model_1.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacfd08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import a saved joblib model\n",
    "\n",
    "loaded_job_model = load(filename=\"gs_random_forest_model_1.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f0fdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make and evaluate joblib prediction\n",
    "\n",
    "joblib_y_preds = loaded_job_model.predict(X_test)\n",
    "evaluate_preds(y_test, joblib_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afc2627",
   "metadata": {},
   "source": [
    "### 7. Putting it all together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1712632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"car-sales-extended-missing-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0faee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b18f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10906c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6d066b",
   "metadata": {},
   "source": [
    "Steps we want to do (all in one cell):\n",
    "\n",
    "    1. Fill missing data\n",
    "    \n",
    "    2. Convert data to numbers\n",
    "    \n",
    "    3. Build a model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b9dab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting data ready\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#Modelling\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Setup random seed\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# Import data and drop rows with missing labels\n",
    "data = pd.read_csv(\"car-sales-extended-missing-data.csv\")\n",
    "data.dropna(subset=[\"Price\"], inplace=True)\n",
    "\n",
    "#Define different features and transformer pipeline\n",
    "categorical_features = [\"Make\", \"Colour\"]\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "door_feature = [\"Doors\"]\n",
    "door_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=4))\n",
    "])\n",
    "\n",
    "numeric_feature = [\"Odometer (KM)\"]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))\n",
    "])\n",
    "\n",
    "#Setup preprocessing steps (fill missing values, then convert to numbers)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "        (\"door\", door_transformer, door_feature),\n",
    "        (\"num\", numeric_transformer, numeric_feature)\n",
    "    ])\n",
    "\n",
    "# Creating a preprocessing and modeling pipeline\n",
    "model = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", RandomForestRegressor())\n",
    "])\n",
    "\n",
    "#Split data \n",
    "X = data.drop(\"Price\", axis=1)\n",
    "y = data[\"Price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#Fit and score the model\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ec7a54",
   "metadata": {},
   "source": [
    "It's also possible to use \"GridSearcjCV\" or \"RandomizedSearchCV\" with our Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4c9e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use GridSearchCV with our regression Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe_grid = {\n",
    "    \"preprocessor__num__imputer__strategy\" : [\"mean\", \"median\"],\n",
    "    \"model__n_estimators\": [100, 1000],\n",
    "    \"model__max_depth\": [None, 5],\n",
    "    \"model__max_features\": [\"auto\"],\n",
    "    \"model__min_samples_split\": [2, 4]\n",
    "    \n",
    "}\n",
    "\n",
    "gs_model = GridSearchCV(model, pipe_grid, cv=5, verbose=2)\n",
    "gs_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8093150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77c59b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
